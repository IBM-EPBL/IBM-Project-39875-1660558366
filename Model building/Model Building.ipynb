{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d3c11c5",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03905c97",
   "metadata": {},
   "source": [
    "Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70720927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15750 images belonging to 9 classes.\n",
      "Found 2250 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255 , shear_range=0.2,\n",
    "zoom_range=0.2,horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "x_train =train_datagen.flow_from_directory('../../../data collection/conversation engine for deaf and dumb/Dataset/training_set',\n",
    "                                           target_size=(64,64),batch_size=900, class_mode='categorical',color_mode='grayscale')\n",
    "x_test =test_datagen.flow_from_directory('../../../data collection/conversation engine for deaf and dumb/Dataset/test_set',\n",
    "                                         target_size=(64,64),batch_size=900, class_mode='categorical', color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e435c6",
   "metadata": {},
   "source": [
    "Train Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eddcf9f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.class_indices \n",
    "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I':8}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0cbccf",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a6f0321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e197af01",
   "metadata": {},
   "source": [
    "## Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fe59752",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10052fe",
   "metadata": {},
   "source": [
    "# Adding Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01189025",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32,(3,3),activation='relu',input_shape=(64,64,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6945f5ba",
   "metadata": {},
   "source": [
    "# Adding Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c41f65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205016fb",
   "metadata": {},
   "source": [
    "# Adding Flatten Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "322f0ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c391910",
   "metadata": {},
   "source": [
    "# Adding Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4f7ca07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(300,activation='relu'))\n",
    "model.add(Dense(512,activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de82d7e0",
   "metadata": {},
   "source": [
    "Adding Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e51640c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(9,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373e75cd",
   "metadata": {},
   "source": [
    "# Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beadb294",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44805b3c",
   "metadata": {},
   "source": [
    "# Fit and Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2ee38ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18/18 [==============================] - 162s 9s/step - loss: 0.9189 - accuracy: 0.6797 - val_loss: 0.3481 - val_accuracy: 0.9120\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 91s 5s/step - loss: 0.1727 - accuracy: 0.9488 - val_loss: 0.2035 - val_accuracy: 0.9489\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 36s 2s/step - loss: 0.0768 - accuracy: 0.9785 - val_loss: 0.2014 - val_accuracy: 0.9636\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 35s 2s/step - loss: 0.0460 - accuracy: 0.9867 - val_loss: 0.2063 - val_accuracy: 0.9596\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 34s 2s/step - loss: 0.0273 - accuracy: 0.9931 - val_loss: 0.1673 - val_accuracy: 0.9707\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 34s 2s/step - loss: 0.0150 - accuracy: 0.9962 - val_loss: 0.2270 - val_accuracy: 0.9684\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 32s 2s/step - loss: 0.0110 - accuracy: 0.9979 - val_loss: 0.1975 - val_accuracy: 0.9756\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 35s 2s/step - loss: 0.0086 - accuracy: 0.9984 - val_loss: 0.2031 - val_accuracy: 0.9764\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 35s 2s/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.1937 - val_accuracy: 0.9764\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 34s 2s/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.2151 - val_accuracy: 0.9778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d02c630dc0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,steps_per_epoch=len(x_train),epochs=10,validation_data=x_test,validation_steps=len(x_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
